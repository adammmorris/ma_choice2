df.ant.filt.alert = df.ant.filt %>% filter(cue %in% c('nocue', 'double')) %>%
group_by(cue, subject) %>%
summarize(correct = mean(correct),
rt = mean(rt)) %>%
arrange(subject) %>%
group_by(subject) %>%
mutate(alerting = rt - lead(rt)) %>%
filter(cue == 'nocue') %>%
dplyr::select(subject, alerting)
# orienting effect
df.ant.filt.orient = df.ant.filt %>% filter(cue %in% c('center', 'spatial')) %>%
group_by(cue, subject) %>%
summarize(correct = mean(correct),
rt = mean(rt)) %>%
arrange(subject) %>%
group_by(subject) %>%
mutate(orienting = rt - lead(rt)) %>%
filter(cue == 'center') %>%
dplyr::select(subject, orienting)
# executive effect
df.ant.filt.exec = df.ant.filt %>% filter(flanker_type %in% c('congruent', 'incongruent')) %>%
group_by(flanker_type, subject) %>%
summarize(correct = mean(correct),
rt = mean(rt)) %>%
arrange(subject) %>%
group_by(subject) %>%
mutate(exec = rt - lag(rt)) %>%
filter(flanker_type == 'incongruent') %>%
dplyr::select(subject, exec)
# combine them
df.ant.networks = df.ant.filt.alert
df.ant.networks$orienting = df.ant.filt.orient$orienting
df.ant.networks$exec = df.ant.filt.exec$exec
rm(df.ant.filt.alert, df.ant.filt.orient, df.ant.filt.exec)
# Clean up demo -----------------------------------------
### MODELS
models = c('Full', 'BinAtts', 'BinWts', 'BinWtsAtts', '1-Att')
models.one.att = c('Multiple', 'Multiple', 'Multiple', 'Multiple', 'One')
models.bin.wts = c('Graded', 'Graded', 'Binary', 'Graded', NA)
models.bin.atts = c('Graded', 'Binary', 'Graded', 'Graded', NA)
models.order = c('Full', 'BinWts', 'BinAtts', 'BinWtsAtts', '1-Att')
df.demo = df.demo %>%
mutate(chosen.model.num = ifelse(one.att == 'One', 5,
ifelse(bin.wts == 'Binary',
ifelse(bin.atts == 'Binary', 4, 3),
ifelse(bin.atts == 'Binary', 2, 1))),
chosen.model = models[chosen.model.num],
chosen.model.fac = factor(chosen.model, models.order, models.order))
## ADD ANT
df.demo$alerting = NA
df.demo$orienting = NA
df.demo$exec = NA
for (i in 1:nrow(df.demo)) {
ant.row = df.ant.networks$subject == df.demo$subject[i]
if (any(ant.row)) {
alerting = df.ant.networks$alerting[ant.row]
if (!is.null(alerting)) df.demo$alerting[i] = alerting;
orienting = df.ant.networks$orienting[ant.row]
if (!is.null(orienting)) df.demo$orienting[i] = orienting;
exec = df.ant.networks$exec[ant.row]
if (!is.null(exec)) df.demo$exec[i] = exec;
}
}
### ADD ICAR
for (i in 1:nrow(df.demo.followup)) {
df.demo$icar_num_correct[df.demo$subject == df.demo.followup$subject[i]] = df.demo.followup$icar_num_correct[i]
}
### MEDITATION EXP
howoften_options = c('Less than once per week', 'About once per week', '2-4 times per week', 'Daily or almost daily')
amount_options = c('5-15 minutes per day', '15-30 minutes per day', '>30 minutes per day')
years_options = c('0-1 years', '1-3 years', '3-5 years', '5+ years')
df.demo = df.demo %>%
mutate(meditation = factor(meditation_exp2, c('Yes', 'No', ''), c('Currently', 'Used to', 'Never')))
### EDUCATION
df.demo = df.demo %>%
mutate(edu.num = as.numeric(factor(edu,
levels=c('Some high school', 'High school', 'Some college',
'2 year degree', '4 year degree', 'Postgraduate/Professional degree/other'))))
### SCALES
battery = c('decisionstyle', 'acs', 'mindfulness', 'sris', 'maia')
max.vals = c(5,4,4,6,6)
# which ones are reversed?
ds.reversed = 6:10
#acs.reversed = c(1,2,3,5,6,8)
acs.reversed = c(1, 2, 3, 6, 7, 8, 11, 12, 15, 16, 20)
mindfulness.reversed = c(2,6,7)
sris.reversed = c(1, 2, 4, 7, 14, 16, 17, 18, 19)
maia.reversed = c()
#ipip.reversed = c(6:10, 17:20, 27:30, 33:40, 48:50)
#bidr.reversed = c(1,3,5,8,9,11,12,13)
reversed = list(ds.reversed, acs.reversed, mindfulness.reversed, sris.reversed, maia.reversed)
# which factors?
ds.factors = c(rep('deliberative',5), rep('intuitive',5))
#acs.factors = c(rep('focusing', 5), rep('shifting', 5))
acs.factors = c(rep('focusing',9), rep('shifting',11))
mindfulness.factors = c('attention', 'present focus', 'acceptance', 'acceptance', 'awareness',
'attention', 'present focus', 'awareness', 'awareness', 'acceptance', 'present focus', 'attention')
sris.factors = c(rep('tendency',12), rep('insight',8))
maia.factors = c(rep('noticing',4),rep('attention regulation',7),rep('emotional awareness',5),rep('body listening',3),rep('trusting',3))
#ipip.factors = c(rep('extraversion',10), rep('agreeableness',10), rep('conscientiousness',10),
#                 rep('stability',10), rep('openness',10))
factors = list(ds.factors, acs.factors, mindfulness.factors, sris.factors, maia.factors)
for (battery.ind in 1:length(battery)) {
name = battery[battery.ind]
reversed.cur = reversed[[battery.ind]]
factors.cur = factors[[battery.ind]]
factors.unique = unique(factors.cur)
max.val.cur = max.vals[battery.ind]
df.demo.followup[,name] = NA
df.demo[,name] = NA
for (i in 1:nrow(df.demo.followup)) {
resp.str = df.demo.followup[i, paste0(name, '_responses')]
if (!is.null(resp.str)) {
demo.row = df.demo$subject == df.demo.followup$subject[i]
resp = as.numeric.vector(resp.str)
resp[reversed.cur] = max.val.cur - resp[reversed.cur] + 1
df.demo.followup[i,name] = mean(resp)
df.demo[demo.row,name] = mean(resp)
for (fac in factors.unique) {
which.items = which(factors.cur == fac)
df.demo.followup[i,paste0(name, '.', fac)] = mean(resp[which.items])
df.demo[demo.row,paste0(name, '.', fac)] = mean(resp[which.items])
}
}
}
}
# choice.domain.fac = factor(choice_domain > median(choice_domain), c(F,T), c('Low', 'High')),
# decisionstyle.fac = factor(decisionstyle > median(decisionstyle), c(F,T), c('Low', 'High')),
# mindfulness.fac = factor(mindfulness > median(mindfulness), c(F,T), c('Low', 'High')),
# sk.fac = factor(sk > median(sk), c(F,T), c('Low', 'High')),
# bidr.fac = factor(bidr > median(bidr), c(F,T), c('Low', 'High')),
# acs.fac = factor(acs > median(acs), c(F,T), c('Low', 'High')),
# Clean up S1 --------------------------------------------------------------
## Stage 1 choices
# make wide df, put each attribute in its own column
atts = unique(df.attributes$attribute)
att.nums = 1:length(atts)
att.nums.str = as.character(att.nums)
atts.opt1 = paste0(atts,'.opt1')
atts.opt2 = paste0(atts,'.opt2')
atts.opt1.enclosed = paste0('`',atts.opt1,'`')
atts.opt2.enclosed = paste0('`',atts.opt2,'`')
atts.opt.diff = paste0(atts,'.diff')
atts.opt.diff.enclosed = paste0('`',atts.opt.diff,'`')
df.s1[,atts.opt1] = NA
df.s1[,atts.opt2] = NA
df.avail.atts = data.frame(matrix(0,nrow = nrow(df.s1), ncol = length(atts)+1))
colnames(df.avail.atts) = c('subject.num', atts.opt1)
df.avail.atts$subject.num = df.s1$subject.num
for (i in 1:nrow(df.s1)) {
cur.atts = as.string.vector(df.s1$attributes[i])
cur.opt1.vals = as.string.vector(df.s1$opt1_values[i])
cur.opt2.vals = as.string.vector(df.s1$opt2_values[i])
cur.att.nums = numeric(length(cur.atts))
for (j in 1:length(cur.atts)) {
#att.row = df.attributes$subject == df.s1$subject[i] & df.attributes$attribute == cur.atts[j]
cur.att.nums[j] = which(cur.atts[j] == atts)
df.s1[i,atts.opt1[cur.att.nums[j]]] = cur.opt1.vals[j]
df.s1[i,atts.opt2[cur.att.nums[j]]] = cur.opt2.vals[j]
df.avail.atts[i,atts.opt1[cur.att.nums[j]]] = 1
}
df.s1$att.nums[i] = as.string(cur.att.nums)
}
# convert attribute values to numerics
for (i in 1:length(atts)) {
cur.att.opt1 = atts.opt1[i]
cur.att.opt2 = atts.opt2[i]
cur.scale = unique(df.attributes$scale[df.attributes$attribute == atts[i]])
if (cur.scale == "") {
df.s1[,cur.att.opt1] = as.numeric(sub('\\ .*', '', df.s1[,cur.att.opt1]))
df.s1[,cur.att.opt2] = as.numeric(sub('\\ .*', '', df.s1[,cur.att.opt2]))
} else {
cur.scale = unlist(strsplit(cur.scale, split = ","))
df.s1[,cur.att.opt1] = as.numeric(factor(df.s1[,cur.att.opt1], cur.scale))
df.s1[,cur.att.opt2] = as.numeric(factor(df.s1[,cur.att.opt2], cur.scale))
}
}
# compute diffs
for (i in 1:length(atts)) {
df.s1[,paste0(atts[i], '.diff')] = df.s1[,atts.opt2[i]] - df.s1[,atts.opt1[i]]
}
# create scaled df.s1 with normalized attribute values (per subject)
df.s1.scaled = df.s1
for (i in df.s1$subject.num) {
subj.rows = df.s1$subject.num == i
df.s1.scaled[subj.rows, c(atts.opt1, atts.opt2, atts.opt.diff)] = scale(df.s1[subj.rows, c(atts.opt1, atts.opt2, atts.opt.diff)])
}
for (i in atts.opt1)
# same thing, except get rid of nan's
df.s1.scaled.nonan = df.s1.scaled
for (i in 1:ncol(df.s1.scaled)) {
df.s1.scaled.nonan[is.na(df.s1.scaled.nonan[,i]),i] = 0
}
df.s1.subj = df.s1 %>% group_by(subject) %>%
summarize(total.time = sum(rt) / 60000,
pct_left = mean(choice == 0),
median_rt = median(rt),
sd_rt = sd(rt),
num_trials = n())
# Clean up S2 / attributes -------------------------------------------------------------
for (i in 1:nrow(df.attributes)) {
cur.att = df.attributes$attribute[i]
subj = df.attributes$subject[i]
cur.scale = df.attributes$scale[i]
rows.demo = df.demo$subject == subj
rows.s2.original = df.s2$subject == subj & df.s2$attribute == cur.att & df.s2$original_or_followup == 'original'
rows.s2.followup = df.s2$subject == subj & df.s2$attribute == cur.att & df.s2$original_or_followup == 'followup'
rows.s2.direction = df.s2$subject == subj & df.s2$attribute == cur.att & df.s2$original_or_followup == 'direction'
lex_q = df.demo$one.att[rows.demo]
weights_q = df.demo$bin.wts[rows.demo]
attributes_q = df.demo$bin.atts[rows.demo]
if (lex_q == 'One') {
# if this is the one...
if (any(rows.s2.original)) {
df.attributes$rating[i] = 1 # should be 1
} else {
df.attributes$rating[i] = 0
}
df.attributes$rating.followup[i] = df.s2$rating[rows.s2.followup] / 100
} else {
if (weights_q == 'Binary') {
df.attributes$rating[i] = df.s2$rating[rows.s2.original]
df.attributes$rating.followup[i] = df.s2$rating[rows.s2.followup] / 100
} else {
df.attributes$rating[i] = df.s2$rating[rows.s2.original] / 100
df.attributes$rating.followup[i] = df.s2$rating[rows.s2.original] / 100
}
}
if (cur.scale == "") {
least = as.numeric(sub('\\ .*', '', df.s2$least_preferred[rows.s2.direction]))
most = as.numeric(sub('\\ .*', '', df.s2$most_preferred[rows.s2.direction]))
bounds = c(df.attributes$lb[i], df.attributes$ub[i])
} else {
cur.scale = unlist(strsplit(cur.scale, ","))
least = which(df.s2$least_preferred[rows.s2.direction] == cur.scale)
most = which(df.s2$most_preferred[rows.s2.direction] == cur.scale)
bounds = c(1, length(cur.scale))
}
df.attributes$most[i] = most
df.attributes$least[i] = least
df.attributes$direction[i] = sign(most - least)
df.attributes$same[i] = most == least
df.attributes$linear[i] = least %in% bounds & most %in% bounds
df.attributes$almost.linear[i] =
(least %in% bounds | (least+1) %in% bounds | (least-1) %in% bounds) &
(most %in% bounds | (most+1) %in% bounds | (most-1) %in% bounds)
df.attributes$lex_q[i] = lex_q
df.attributes$weights_q[i] = weights_q
df.attributes$attributes_q[i] = attributes_q
df.attributes$chosen.model[i] = df.demo$chosen.model[rows.demo]
df.attributes$chosen.model.num[i] = df.demo$chosen.model.num[rows.demo]
df.attributes$chosen.model.fac[i] = df.demo$chosen.model.fac[rows.demo]
}
df.attributes = df.attributes %>%
mutate(rating.signed = rating * direction,
rating.followup.signed = rating.followup * direction)
# Import modeling results -------------------------------------------------
version = '';
## get cross-validation results
# ll version
df.cv.norm = read.csv(paste0('cv_results_normalized',version,'.csv'), header = F)
colnames(df.cv.norm) = models
df.cv.norm$subject.num = df.demo$subject.num
for (i in 1:nrow(df.demo)) {
df.demo$best.model.nums[i] = list(which(df.cv.norm[i,1:length(models)] == max(df.cv.norm[i,1:length(models)], na.rm = T)))
df.demo$multiple.bests[i] = length(df.demo$best.model.nums[i][[1]]) > 1
df.demo$best.model.num[i] = max(df.demo$best.model.nums[i][[1]])
df.attributes$best.model.num[df.attributes$subject == df.demo$subject[i]] = df.demo$best.model.num[i]
df.demo$chosen.model.ll[i] = df.cv.norm[i,df.demo$chosen.model.num[i]]
df.demo$chosen.model.rank[i] = rank(-df.cv.norm[i,1:length(models)])[df.demo$chosen.model.num[i]]
df.demo$chose.correct.model[i] = df.demo$chosen.model.num[i] %in% df.demo$best.model.nums[i][[1]]
}
df.demo = df.demo %>%
mutate(best.model = models[best.model.num],
best.model.fac = factor(best.model, models.order, models.order),
one.att.real = factor(models.one.att[best.model.num], one.att.levels),
bin.wts.real = factor(models.bin.wts[best.model.num], bin.wts.levels),
bin.atts.real = factor(models.bin.atts[best.model.num], bin.atts.levels))
# get likelihoods of best model
df.cv.best = read.csv(paste0('cv_results_best',version,'.csv'), header = F)
df.demo$best.model.ll.magnitude = df.cv.best$V3
df.demo$below.chance = df.cv.best$V2
# get non-normalized version
df.cv = read.csv(paste0('cv_results',version,'.csv'), header = F)
colnames(df.cv) = models
df.cv$subject.num = df.demo$subject.num
df.cv$subject = df.demo$subject
df.demo$avg.model.ll = rowMeans(df.cv[,1:length(models)])
df.demo$var.model.ll = apply(df.cv[,1:length(models)], 1, var)
df.demo$sd.model.ll = sqrt(df.demo$var.model.ll)
# rounded version
df.cv.rnd = read.csv(paste0('cv_results_rounded',version,'.csv'), header = F)
colnames(df.cv.rnd) = models
for (i in 1:nrow(df.demo)) {
df.demo$best.model.nums.rnd[i] = list(which(df.cv.rnd[i,1:length(models)] == max(df.cv.rnd[i,1:length(models)], na.rm = T)))
df.demo$multiple.bests.rnd[i] = length(df.demo$best.model.nums.rnd[i][[1]]) > 1
df.demo$best.model.num.rnd[i] = max(df.demo$best.model.nums.rnd[i][[1]])
df.attributes$best.model.num.rnd[df.attributes$subject == df.demo$subject[i]] = df.demo$best.model.num.rnd[i]
df.demo$chosen.model.rnd[i] = df.cv.rnd[i,df.demo$chosen.model.num[i]]
df.demo$best.model.rnd.magnitude[i] = df.cv.rnd[i,df.demo$best.model.num.rnd[i]]
df.demo$best.model.rnd.magnitude2[i] = df.cv.rnd[i,df.demo$best.model.num[i]]
df.demo$chosen.model.rank.rnd[i] = rank(-df.cv.rnd[i,1:length(models)])[df.demo$chosen.model.num[i]]
df.demo$chose.correct.model.rnd[i] = df.demo$chosen.model.num[i] %in% df.demo$best.model.nums.rnd[i][[1]]
df.demo$model.fits.agree[i] = df.demo$best.model.num[i] %in% df.demo$best.model.nums.rnd[i][[1]]
}
df.demo = df.demo %>%
mutate(best.model.rnd = models[best.model.num.rnd],
best.model.fac.rnd = factor(best.model.rnd, models.order, models.order))
df.demo$avg.model.rnd = rowMeans(df.cv.rnd[,1:length(models)])
df.demo$var.model.rnd = apply(df.cv.rnd[,1:length(models)], 1, var)
## get weights
df.fitted.wad = read.csv('fitted_empirical_weights_WAD.csv', header = F)
df.fitted.wp = read.csv('fitted_empirical_weights_WP.csv', header = F)
df.fitted.ew = read.csv('fitted_empirical_weights_EW.csv', header = F)
df.fitted.tal = read.csv('fitted_empirical_weights_TAL.csv', header = F)
df.fitted.lex.raw = read.csv('fitted_empirical_weights_LEX.csv', header = F)
colnames(df.fitted.wad) = atts
colnames(df.fitted.wp) = atts
colnames(df.fitted.ew) = atts
colnames(df.fitted.tal) = atts
df.fitted.lex = df.fitted.wad
for (i in 1:nrow(df.fitted.lex)) {
for (att in 1:length(atts)) {
if (df.fitted.lex.raw$V1[i] == att) {
df.fitted.lex[i,att] = ifelse(df.fitted.lex.raw$V2[i] == 1, 1, -1)
} else {
df.fitted.lex[i,att] = 0
}
}
}
fitted.weights = list(df.fitted.wad, df.fitted.wp, df.fitted.ew, df.fitted.tal, df.fitted.lex)
for (i in 1:nrow(df.attributes)) {
df.attributes$fitted.weight[i] = fitted.weights[[df.attributes$chosen.model.num[i]]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.best[i] = fitted.weights[[df.attributes$best.model.num[i]]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.wad[i] = fitted.weights[[1]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.wp[i] = fitted.weights[[2]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.ew[i] = fitted.weights[[3]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.tal[i] = fitted.weights[[4]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.lex[i] = fitted.weights[[5]][df.attributes$subject.num[i],df.attributes$attribute[i]]
}
df.attributes = df.attributes %>%
mutate(fitted.weight.abs = abs(fitted.weight),
fitted.weight.best.abs = abs(fitted.weight.best),
fitted.weight.wad.abs = abs(fitted.weight.wad),
error = fitted.weight - rating.signed,
error.sq = error ^ 2,
error.abs = fitted.weight.abs - rating,
error.abs.sq = error.abs ^ 2,
error.followup = fitted.weight.wad - rating.followup.signed,
error.followup.sq = error.followup ^ 2,
error.followup.abs = fitted.weight.wad.abs - rating.followup,
error.followup.abs.sq = error.followup.abs ^ 2,
error.best = fitted.weight.best - rating.signed,
error.best.sq = error.best ^ 2,
error.best.abs = fitted.weight.best.abs - rating,
error.best.abs.sq = error.best.abs ^ 2,
error.followup.best = fitted.weight.best - rating.followup.signed,
error.followup.best.sq = error.followup.best ^ 2,
error.followup.best.abs = fitted.weight.best.abs - rating.followup,
error.followup.best.abs.sq = error.followup.best.abs ^ 2)
# get normalized per-subject fitted weights and ratings
subjects = unique(df.attributes$subject.num)
for (i in subjects) {
cur.rows = df.attributes$subject.num == i
df.attributes$rating.signed.scaled[cur.rows] = scale(df.attributes$rating.signed[cur.rows])
df.attributes$fitted.weight.scaled[cur.rows] = scale(df.attributes$fitted.weight[cur.rows])
#df.s2$fitted.weight.lm.scaled[cur.rows] = scale(df.s2$fitted.weight.lm[cur.rows])
}
# get subject-level accuracies
df.attributes.subj = df.attributes %>% group_by(subject) %>%
summarize(num_same = sum(same & (rating > 10)),
accuracy = cor(fitted.weight, rating.signed, method = 'kendall'),
accuracy.abs = cor(fitted.weight.abs, rating, method = 'kendall'),
accuracy.followup = cor(fitted.weight.wad, rating.followup.signed, method = 'kendall'),
accuracy.followup.abs = cor(fitted.weight.wad.abs, rating.followup, method = 'kendall'),
accuracy.scaled = cor(fitted.weight.scaled, rating.signed.scaled, method = 'kendall'),
accuracy.best = cor(fitted.weight.best, rating.signed, method = 'kendall'),
accuracy.followup.best = cor(fitted.weight.best, rating.followup.signed, method = 'kendall'),
mse = mean(error.sq),
mse.abs = mean(error.abs.sq),
mse.followup = mean(error.followup.sq),
mse.followup.abs = mean(error.followup.abs.sq),
mse.best = mean(error.best.sq),
mse.best.abs = mean(error.best.abs.sq),
mse.followup.best = mean(error.followup.best.sq),
mse.followup.best.abs = mean(error.followup.best.abs.sq))
for (i in 1:nrow(df.demo)) {
att.row = df.attributes.subj$subject == df.demo$subject[i]
df.demo$accuracy[i] = df.attributes.subj$accuracy[att.row]
df.demo$accuracy.abs[i] = df.attributes.subj$accuracy.abs[att.row]
df.demo$accuracy.followup[i] = df.attributes.subj$accuracy.followup[att.row]
df.demo$accuracy.followup.abs[i] = df.attributes.subj$accuracy.followup.abs[att.row]
df.demo$accuracy.scaled[i] = df.attributes.subj$accuracy.scaled[att.row]
df.demo$accuracy.best[i] = df.attributes.subj$accuracy.best[att.row]
df.demo$accuracy.followup.best[i] = df.attributes.subj$accuracy.followup.best[att.row]
df.demo$mse[i] = df.attributes.subj$mse[att.row]
df.demo$mse.abs[i] = df.attributes.subj$mse.abs[att.row]
df.demo$mse.followup[i] = df.attributes.subj$mse.followup[att.row]
df.demo$mse.followup.abs[i] = df.attributes.subj$mse.followup.abs[att.row]
df.demo$mse.best[i] = df.attributes.subj$mse.best[att.row]
df.demo$mse.best.abs[i] = df.attributes.subj$mse.best.abs[att.row]
df.demo$mse.followup.best[i] = df.attributes.subj$mse.followup.best[att.row]
df.demo$mse.followup.best.abs[i] = df.attributes.subj$mse.followup.best.abs[att.row]
}
## get inv temps
df.temp.wad = read.csv('fitted_empirical_temps_WAD.csv', header = F)
df.temp.wp = read.csv('fitted_empirical_temps_WP.csv', header = F)
df.temp.ew = read.csv('fitted_empirical_temps_EW.csv', header = F)
df.temp.tal = read.csv('fitted_empirical_temps_TAL.csv', header = F)
df.temp.lex = read.csv('fitted_empirical_temps_LEX.csv', header = F)
df.temp = bind_cols(df.temp.wad, df.temp.wp, df.temp.ew, df.temp.tal, df.temp.lex)
for (i in 1:nrow(df.demo)) {
df.demo$inv.temp[i] = df.temp[i,df.demo$best.model.num[i]]
}
## get avg option diffs
df.optiondiffs = read.csv('option_diffs.csv', header = F)
df.demo$option.diff.avg = df.optiondiffs$V1
df.demo$option.diff.choiceprob = df.optiondiffs$V2
df.demo$option.diff.sd = df.optiondiffs$V3
# these are my weird attempts at doing split-half reliability estimates
# df.s2.subj.split = df.s2 %>% mutate(trial_half = factor(trial %in% combs[,i], c(F,T), c('First Half', 'Second Half'))) %>%
#   group_by(subject, trial_half) %>%
#   summarize(accuracy = cor(fitted.weight.abs, rating))
# combs = combn(1:18,9)
# df.s2.grouped = df.s2 %>% group_by(subject)
# shr = numeric(ncol(combs))
# for (i in 1:ncol(combs)) {
#   acc1 = (df.s2.grouped %>% filter(trial %in% combs[,i]) %>% summarize(accuracy = cor(fitted.weight.abs, rating)))$accuracy
#   acc2 = (df.s2.grouped %>% filter(!(trial %in% combs[,i])) %>% summarize(accuracy = cor(fitted.weight.abs, rating)))$accuracy
#   shr[i] = cor(acc1, acc2)
# }
# Browser events ----------------------------------------------------------
df.browser = read.csv('browser_events.csv', stringsAsFactors = F)
df.browser.subj = df.browser %>%
filter(browser_event == 'blur') %>%
group_by(subject) %>%
summarize(num.blur = n())
# Do filtering ---------------------------------------------------------
exclude.subj = c()
for (subj in subjlist) {
demo.row = df.demo$subject == subj
s1.subj = df.s1.subj$subject == subj
browser.row = df.browser.subj$subject == subj
if (subj %in% exclude.subj.ant |
df.demo$instruction_times_median[demo.row] < 2 |
(!is.na(df.demo$instruction_times_followup_median[demo.row]) && df.demo$instruction_times_followup_median[demo.row] < 2) |
df.s1.subj$pct_left[s1.subj] > .8 |
df.s1.subj$pct_left[s1.subj] < .2 |
df.s1.subj$num_trials != 75 |
df.attributes.subj$num_same[df.attributes.subj$subject == subj] > 0 |
df.demo$attention[demo.row] < .5 |
df.demo$below.chance[demo.row] |
(any(browser.row) && df.browser.subj$num.blur[df.browser.subj$subject == subj] > 20)) {
exclude.subj = c(exclude.subj, subj)
}
}
df.demo.filt = df.demo %>% filter(!(subject %in% exclude.subj))
df.s1.filt = df.s1 %>% filter(!(subject %in% exclude.subj))
df.s2.filt = df.s2 %>% filter(!(subject %in% exclude.subj))
df.attributes.filt = df.attributes %>% filter(!(subject %in% exclude.subj))
df.attributes.subj.filt = df.attributes.subj %>% filter(!(subject %in% exclude.subj))
df.cv.filt = df.cv %>% filter(!(subject %in% exclude.subj))
ggplot(df.demo.filt, aes(x = option.diff.avg, y = mse.best)) +
geom_point(color='gray') +
geom_smooth(method='lm',color='gray') +
theme_black() +
labs(x = 'Inverse temperature', y = 'Mean squared error')
ggplot(df.demo.filt, aes(x = option.diff.avg, y = chosen.model.ll)) +
geom_point(color='gray') +
geom_smooth(method='lm',color='gray') +
theme_black() +
labs(x = 'Inverse temperature', y = 'Chosen model likelihood\n(normalized)')
ggplot(df.demo.filt, aes(x = option.diff.sd, y = mse.best)) +
geom_point(color='gray') +
geom_smooth(method='lm',color='gray') +
theme_black() +
labs(x = 'Inverse temperature', y = 'Mean squared error')
ggplot(df.demo.filt, aes(x = option.diff.choiceprob, y = mse.best)) +
geom_point(color='gray') +
geom_smooth(method='lm',color='gray') +
theme_black() +
labs(x = 'Inverse temperature', y = 'Mean squared error')
summary(lm(mse.best ~ best.model.ll.magnitude + option.diff.avg, data = df.demo.filt))
summary(lm(mse.best ~ best.model.ll.magnitude + option.diff.avg + option.diff.sd, data = df.demo.filt))
summary(lm(chosen.model.ll ~ best.model.ll.magnitude + option.diff.avg + option.diff.sd, data = df.demo.filt))
summary(lm(mse.best ~ option.diff.avg + option.diff.sd, data = df.demo.filt))
summary(lm(chosen.model.ll ~ option.diff.avg + option.diff.sd, data = df.demo.filt))
summary(lm(mse.best ~ option.diff.choiceprob + option.diff.sd, data = df.demo.filt))
summary(lm(chosen.model.ll ~ option.diff.choiceprob + option.diff.sd, data = df.demo.filt))
ggplot(df.demo.filt, aes(x = option.diff.choiceprob, y = option.diff.sd)) +
geom_point(color='gray') +
geom_smooth(method='lm',color='gray') +
theme_black() +
labs(x = 'Inverse temperature', y = 'Mean squared error')
ggplot(df.demo.filt, aes(x = option.diff.choiceprob, y = chosen.model.ll)) +
geom_point(color='gray') +
geom_smooth(method='lm',color='gray') +
theme_black() +
labs(x = 'Inverse temperature', y = 'Chosen model likelihood\n(normalized)')
ggplot(df.demo.filt, aes(x = option.diff.choiceprob, y = mse.best)) +
geom_point(color='gray') +
geom_smooth(method='lm',color='gray') +
theme_black() +
labs(x = 'Inverse temperature', y = 'Mean squared error')
summary(lm(mse.best ~ option.diff.choiceprob, data = df.demo.filt))
summary(lm(mse.best ~ option.diff.sd, data = df.demo.filt))
summary(lm(chosen.model.ll ~ option.diff.choiceprob, data = df.demo.filt))
summary(lm(mse.best ~ option.diff.choiceprob, data = df.demo.filt))
summary(lm(mse.best ~ inv.temp + option.diff.choiceprob, data = df.demo.filt))
summary(lm(mse.best ~  option.diff.avg, data = df.demo.filt))
View(df.s2.filt)
View(df.attributes)
