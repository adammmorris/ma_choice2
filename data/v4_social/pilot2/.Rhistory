cur.opt1.vals = as.string.vector(df.s1$opt1_values[i])
cur.opt2.vals = as.string.vector(df.s1$opt2_values[i])
cur.att.nums = numeric(length(cur.atts))
cur.atts.order = numeric(length(cur.atts))
for (j in 1:length(cur.atts)) {
#att.row = df.attributes$subject == df.s1$subject[i] & df.attributes$attribute == cur.atts[j]
cur.att.nums[j] = which(cur.atts[j] == atts)
df.s1[i,atts.opt1[cur.att.nums[j]]] = cur.opt1.vals[j]
df.s1[i,atts.opt2[cur.att.nums[j]]] = cur.opt2.vals[j]
df.avail.atts[i,atts.opt1[cur.att.nums[j]]] = 1
cur.atts.order[j] = which(atts[j] == cur.atts)
}
df.s1$atts.order[i] = as.string(cur.atts.order)
df.s1$att.nums[i] = as.string(cur.att.nums)
}
# convert attribute values to numerics
for (i in 1:length(atts)) {
cur.att.opt1 = atts.opt1[i]
cur.att.opt2 = atts.opt2[i]
cur.scale = unique(df.attributes$scale[df.attributes$attribute == atts[i]])
if (cur.scale == "") {
df.s1[,cur.att.opt1] = as.numeric(sub('\\ .*', '', df.s1[,cur.att.opt1]))
df.s1[,cur.att.opt2] = as.numeric(sub('\\ .*', '', df.s1[,cur.att.opt2]))
} else {
cur.scale = unlist(strsplit(cur.scale, split = ","))
df.s1[,cur.att.opt1] = as.numeric(factor(df.s1[,cur.att.opt1], cur.scale))
df.s1[,cur.att.opt2] = as.numeric(factor(df.s1[,cur.att.opt2], cur.scale))
}
}
# compute diffs
for (i in 1:length(atts)) {
df.s1[,paste0(atts[i], '.diff')] = df.s1[,atts.opt2[i]] - df.s1[,atts.opt1[i]]
}
# create scaled df.s1 with normalized attribute values (per subject)
df.s1.scaled = df.s1
for (i in df.s1$subject.num) {
subj.rows = df.s1$subject.num == i
df.s1.scaled[subj.rows, c(atts.opt1, atts.opt2, atts.opt.diff)] = scale(df.s1[subj.rows, c(atts.opt1, atts.opt2, atts.opt.diff)])
}
# same thing, except get rid of nan's
df.s1.scaled.nonan = df.s1.scaled
for (i in 1:ncol(df.s1.scaled)) {
df.s1.scaled.nonan[is.na(df.s1.scaled.nonan[,i]),i] = 0
}
df.s1.subj = df.s1 %>%
group_by(subject) %>%
summarize(total.time = sum(rt) / 60000,
pct_left = mean(choice == 0),
median_rt = median(rt),
sd_rt = sd(rt),
num_trials = n())
for (i in 1:nrow(df.attributes)) {
cur.att = df.attributes$attribute[i]
subj = df.attributes$subject[i]
cur.scale = df.attributes$scale[i]
rows.demo = df.demo$subject == subj
rows.s2.wad = df.s2$subject == subj & df.s2$attribute == cur.att & df.s2$type == 'wad_att_rating'
rows.s2.ew = df.s2$subject == subj & df.s2$attribute == cur.att & df.s2$type == 'ew_att_rating'
rows.s2.lex = df.s2$subject == subj & df.s2$attribute == cur.att & df.s2$type == 'lex_att_rating'
rows.s2.direction = df.s2$subject == subj & df.s2$attribute == cur.att & df.s2$type == 'direction'
# if this is the one...
if (any(rows.s2.lex)) {
df.attributes$rating.lex[i] = 1 # should be 1
} else {
df.attributes$rating.lex[i] = 0
}
if (any(rows.s2.ew)) {
df.attributes$rating.ew[i] = 1 # should be 1
} else {
df.attributes$rating.ew[i] = 0
}
df.attributes$rating.wad[i] = df.s2$rating[rows.s2.wad] / 100
# if (cur.scale == "") {
#   least = as.numeric(sub('\\ .*', '', df.s2$least_preferred[rows.s2.direction]))
#   most = as.numeric(sub('\\ .*', '', df.s2$most_preferred[rows.s2.direction]))
#   bounds = c(df.attributes$lb[i], df.attributes$ub[i])
# } else {
#   cur.scale = unlist(strsplit(cur.scale, ","))
#   least = which(df.s2$least_preferred[rows.s2.direction] == cur.scale)
#   most = which(df.s2$most_preferred[rows.s2.direction] == cur.scale)
#   bounds = c(1, length(cur.scale))
# }
df.attributes$most[i] = NA
df.attributes$least[i] = NA
df.attributes$direction[i] = ifelse(df.s2$rating[rows.s2.direction][1] == 1, 1, -1)
df.attributes$same[i] = F#most == least
#df.attributes$linear[i] = least %in% bounds & most %in% bounds
df.attributes$linear[i] = all(df.s2$rating[rows.s2.direction] == 1) | all(df.s2$rating[rows.s2.direction] == 0)
df.attributes$almost.linear[i] = df.attributes$linear[i] | min(table(df.s2$rating[rows.s2.direction])) <= 1
df.attributes$lex_real[i] = df.demo$lex_real[rows.demo]
df.attributes$binwts_real[i] = df.demo$binwts_real[rows.demo]
df.attributes$binatts_real[i] = df.demo$binatts_real[rows.demo]
df.attributes$chosen.oneatt[i] = df.demo$chosen.oneatt[rows.demo]
df.attributes$chosen.binwts[i] = df.demo$chosen.binwts[rows.demo]
df.attributes$chosen.binatts[i] = df.demo$chosen.binatts[rows.demo]
df.attributes$chosen.model[i] = df.demo$chosen.model[rows.demo]
df.attributes$chosen.model.num[i] = df.demo$chosen.model.num[rows.demo]
df.attributes$chosen.model.fac[i] = df.demo$chosen.model.fac[rows.demo]
df.attributes$rating.chosen[i] = ifelse(df.demo$chosen.oneatt[rows.demo] == 'One',
df.attributes$rating.lex[i],
ifelse(df.demo$chosen.binwts[rows.demo] == 'Binary',
df.attributes$rating.ew[i],
df.attributes$rating.wad[i]))
}
df.attributes = df.attributes %>%
mutate(rating.wad.signed = rating.wad * direction,
rating.ew.signed = rating.ew * direction,
rating.lex.signed = rating.lex * direction,
rating.chosen.signed = rating.chosen * direction)
write.table(df.s1 %>% dplyr::select(subject.num, all_of(atts.opt1)), 'modeling_opts1.csv', row.names = F, col.names = F, sep = ",")
write.table(df.s1 %>% dplyr::select(subject.num, all_of(atts.opt2)), 'modeling_opts2.csv', row.names = F, col.names = F, sep = ",")
write.table(df.s1 %>% dplyr::select(subject.num, choice) %>% mutate(choice = choice + 1), 'modeling_choice.csv', row.names = F, col.names = F, sep = ",")
write.table(df.avail.atts, 'modeling_avail_atts.csv', row.names = F, col.names = F, sep = ",")
View(df.s1)
unique(df.s1$`Distance from home.opt1`)
sort(unique(df.s1$`Distance from home.opt1`))
atts
length(atts)
i = 1
df.s1[,atts.opt1[i]]
min(df.s1[,atts.opt1[i]])
atts.lower = numeric(length(atts))
atts.upper = numeric(length(atts))
for (i in 1:length(atts)) {
att.vals = c(df.s1[,atts.opt1[i]],df.s1[,atts.opt2[i]])
atts.lower[i] = min(att.vals)
atts.upper[i] = max(att.vals)
}
atts.lower
atts.upper
write.table(atts.lower, 'modeling_lb.csv', row.names = F, col.names = F, sep = ",")
write.table(atts.upper, 'modeling_ub.csv', row.names = F, col.names = F, sep = ",")
version = '';
## get cross-validation results
# non-normalized version
df.cv = read.csv(paste0('cv_results',version,'.csv'), header = F)
colnames(df.cv) = models
df.cv$subject.num = df.demo$subject.num
df.cv$subject = df.demo$subject
df.demo$avg.model.ll = rowMeans(df.cv[,1:length(models)])
df.demo$var.model.ll = apply(df.cv[,1:length(models)], 1, var)
df.demo$sd.model.ll = sqrt(df.demo$var.model.ll)
# likelihoods of best model
df.cv.best = read.csv(paste0('cv_results_best',version,'.csv'), header = F)
df.cv.best$subject = df.demo$subject
df.demo$best.model.ll.magnitude = df.cv.best$V3
df.demo$below.chance = df.cv.best$V2
# ll version
df.cv.norm = read.csv(paste0('cv_results_normalized',version,'.csv'), header = F)
colnames(df.cv.norm) = models
df.cv.norm$subject.num = df.demo$subject.num
df.cv.norm$subject = df.demo$subject
for (i in 1:nrow(df.demo)) {
df.demo$best.model.nums[i] = list(which(df.cv.norm[i,1:length(models)] == max(df.cv.norm[i,1:length(models)], na.rm = T)))
df.demo$multiple.bests[i] = length(df.demo$best.model.nums[i][[1]]) > 1
df.demo$best.model.num[i] = max(df.demo$best.model.nums[i][[1]])
df.attributes$best.model.num[df.attributes$subject == df.demo$subject[i]] = df.demo$best.model.num[i]
df.demo$chosen.model.ll[i] = df.cv.norm[i,df.demo$chosen.model.num[i]]
df.demo$chosen.model.ll.unnormed[i] = df.cv[i,df.demo$chosen.model.num[i]]
df.demo$chosen.model.rank[i] = rank(-df.cv.norm[i,1:length(models)])[df.demo$chosen.model.num[i]]
df.demo$chose.correct.model[i] = df.demo$chosen.model.num[i] %in% df.demo$best.model.nums[i][[1]]
}
df.demo = df.demo %>%
mutate(best.model = models[best.model.num],
best.model.fac = factor(best.model, models.order, models.order),
best.model.oneatt = factor(models.one.att[best.model.num], one.att.levels),
best.model.binwts = factor(models.bin.wts[best.model.num], bin.wts.levels),
best.model.binatts = factor(models.bin.atts[best.model.num], bin.atts.levels),
chosen.model.dist = best.model.ll.magnitude - chosen.model.ll.unnormed)
for (i in 1:nrow(df.attributes)) {
df.attributes$rating.best[i] = ifelse(df.demo$best.model.oneatt[rows.demo] == 'One',
df.attributes$rating.lex[i],
ifelse(df.demo$best.model.binwts[rows.demo] == 'Binary',
df.attributes$rating.ew[i],
df.attributes$rating.wad[i]))
}
df.attributes = df.attributes %>% mutate(rating.best.signed = rating.best * direction)
# rounded version
df.cv.rnd = read.csv(paste0('cv_results_rounded',version,'.csv'), header = F)
colnames(df.cv.rnd) = models
for (i in 1:nrow(df.demo)) {
df.demo$best.model.nums.rnd[i] = list(which(df.cv.rnd[i,1:length(models)] == max(df.cv.rnd[i,1:length(models)], na.rm = T)))
df.demo$multiple.bests.rnd[i] = length(df.demo$best.model.nums.rnd[i][[1]]) > 1
df.demo$best.model.num.rnd[i] = max(df.demo$best.model.nums.rnd[i][[1]])
df.attributes$best.model.num.rnd[df.attributes$subject == df.demo$subject[i]] = df.demo$best.model.num.rnd[i]
df.demo$chosen.model.rnd[i] = df.cv.rnd[i,df.demo$chosen.model.num[i]]
df.demo$best.model.rnd.magnitude[i] = df.cv.rnd[i,df.demo$best.model.num.rnd[i]]
df.demo$best.model.rnd.magnitude2[i] = df.cv.rnd[i,df.demo$best.model.num[i]]
df.demo$chosen.model.rank.rnd[i] = rank(-df.cv.rnd[i,1:length(models)])[df.demo$chosen.model.num[i]]
df.demo$chose.correct.model.rnd[i] = df.demo$chosen.model.num[i] %in% df.demo$best.model.nums.rnd[i][[1]]
df.demo$model.fits.agree[i] = df.demo$best.model.num[i] %in% df.demo$best.model.nums.rnd[i][[1]]
}
df.demo = df.demo %>%
mutate(best.model.rnd = models[best.model.num.rnd],
best.model.fac.rnd = factor(best.model.rnd, models.order, models.order))
df.demo$avg.model.rnd = rowMeans(df.cv.rnd[,1:length(models)])
df.demo$var.model.rnd = apply(df.cv.rnd[,1:length(models)], 1, var)
## get weights
df.fitted.wad = read.csv('fitted_empirical_weights_WAD.csv', header = F)
df.fitted.wp = read.csv('fitted_empirical_weights_WP.csv', header = F)
df.fitted.ew = read.csv('fitted_empirical_weights_EW.csv', header = F)
df.fitted.tal = read.csv('fitted_empirical_weights_TAL.csv', header = F)
df.fitted.lex.raw = read.csv('fitted_empirical_weights_LEXNB.csv', header = F)
df.fitted.lexb.raw = read.csv('fitted_empirical_weights_LEXB.csv', header = F)
colnames(df.fitted.wad) = atts
colnames(df.fitted.wp) = atts
colnames(df.fitted.ew) = atts
colnames(df.fitted.tal) = atts
df.fitted.lex = df.fitted.wad
for (i in 1:nrow(df.fitted.lex)) {
for (att in 1:length(atts)) {
if (df.fitted.lex.raw$V1[i] == att) {
df.fitted.lex[i,att] = ifelse(df.fitted.lex.raw$V2[i] == 1, 1, -1)
} else {
df.fitted.lex[i,att] = 0
}
}
}
df.fitted.lexb = df.fitted.wad
for (i in 1:nrow(df.fitted.lexb)) {
for (att in 1:length(atts)) {
if (df.fitted.lexb.raw$V1[i] == att) {
df.fitted.lexb[i,att] = ifelse(df.fitted.lexb.raw$V2[i] == 1, 1, -1)
} else {
df.fitted.lexb[i,att] = 0
}
}
}
fitted.weights = list(df.fitted.wad, df.fitted.wp, df.fitted.ew, df.fitted.tal, df.fitted.lex, df.fitted.lexb)
for (i in 1:nrow(df.attributes)) {
df.attributes$fitted.weight.chosen[i] = fitted.weights[[df.attributes$chosen.model.num[i]]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.best[i] = fitted.weights[[df.attributes$best.model.num[i]]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.wad[i] = fitted.weights[[1]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.wp[i] = fitted.weights[[2]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.ew[i] = fitted.weights[[3]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.tal[i] = fitted.weights[[4]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.lex[i] = fitted.weights[[5]][df.attributes$subject.num[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.lexb[i] = fitted.weights[[6]][df.attributes$subject.num[i],df.attributes$attribute[i]]
}
df.attributes = df.attributes %>%
mutate(fitted.weight.chosen.abs = abs(fitted.weight.chosen),
fitted.weight.best.abs = abs(fitted.weight.best),
fitted.weight.wad.abs = abs(fitted.weight.wad))
# error = fitted.weight - rating.signed,
# error.sq = error ^ 2,
# error.abs = fitted.weight.abs - rating,
# error.abs.sq = error.abs ^ 2,
# error.followup = fitted.weight.wad - rating.followup.signed,
# error.followup.sq = error.followup ^ 2,
# error.followup.abs = fitted.weight.wad.abs - rating.followup,
# error.followup.abs.sq = error.followup.abs ^ 2,
# error.best = fitted.weight.best - rating.signed,
# error.best.sq = error.best ^ 2,
# error.best.abs = fitted.weight.best.abs - rating,
# error.best.abs.sq = error.best.abs ^ 2,
# error.followup.best = fitted.weight.best - rating.followup.signed,
# error.followup.best.sq = error.followup.best ^ 2,
# error.followup.best.abs = fitted.weight.best.abs - rating.followup,
# error.followup.best.abs.sq = error.followup.best.abs ^ 2)
# get normalized per-subject fitted weights and ratings
subjects = unique(df.attributes$subject.num)
for (i in subjects) {
cur.rows = df.attributes$subject.num == i
df.attributes$rating.wad.signed.scaled[cur.rows] = scale(df.attributes$rating.wad.signed[cur.rows])
df.attributes$fitted.weight.chosen.scaled[cur.rows] = scale(df.attributes$fitted.weight.chosen[cur.rows])
#df.s2$fitted.weight.lm.scaled[cur.rows] = scale(df.s2$fitted.weight.lm[cur.rows])
}
# get subject-level accuracies
df.attributes.subj = df.attributes %>% group_by(subject) %>%
summarize(num_same = sum(same & (rating.wad > .1)),
linear = mean(linear),
accuracy.wad.chosen = cor(fitted.weight.chosen, rating.wad.signed, method = 'kendall'),
accuracy.wad.best = cor(fitted.weight.best, rating.wad.signed, method = 'kendall'),
accuracy.ew.chosen = cor(fitted.weight.chosen, rating.ew.signed, method = 'kendall'),
accuracy.ew.best = cor(fitted.weight.best, rating.ew.signed, method = 'kendall'),
accuracy.lex.chosen = cor(fitted.weight.chosen, rating.lex.signed, method = 'kendall'),
accuracy.lex.best = cor(fitted.weight.best, rating.lex.signed, method = 'kendall'),
accuracy.chosen.best = cor(fitted.weight.best, rating.chosen.signed, method = 'kendall'),
accuracy.chosen.chosen = cor(fitted.weight.chosen, rating.chosen.signed, method = 'kendall'),
accuracy.best.best = cor(fitted.weight.best, rating.best.signed))
# accuracy.abs = cor(fitted.weight.abs, rating, method = 'kendall'),
# accuracy.followup = cor(fitted.weight.wad, rating.followup.signed, method = 'kendall'),
# accuracy.followup.abs = cor(fitted.weight.wad.abs, rating.followup, method = 'kendall'),
# accuracy.scaled = cor(fitted.weight.scaled, rating.signed.scaled, method = 'kendall'),
# accuracy.best = cor(fitted.weight.best, rating.signed, method = 'kendall'),
# accuracy.followup.best = cor(fitted.weight.best, rating.followup.signed, method = 'kendall'),
# mse = mean(error.sq),
# mse.abs = mean(error.abs.sq),
# mse.followup = mean(error.followup.sq),
# mse.followup.abs = mean(error.followup.abs.sq),
# mse.best = mean(error.best.sq),
# mse.best.abs = mean(error.best.abs.sq),
# mse.followup.best = mean(error.followup.best.sq),
# mse.followup.best.abs = mean(error.followup.best.abs.sq))
cols.to.xfer = colnames(df.attributes.subj %>% select(!subject))
for (i in 1:nrow(df.demo)) {
att.row = df.attributes.subj$subject == df.demo$subject[i]
for (cur.col in cols.to.xfer) {
df.demo[i,cur.col] = df.attributes.subj[att.row, cur.col]
}
# df.demo$accuracy[i] = df.attributes.subj$accuracy[att.row]
# df.demo$accuracy.abs[i] = df.attributes.subj$accuracy.abs[att.row]
# df.demo$accuracy.followup[i] = df.attributes.subj$accuracy.followup[att.row]
# df.demo$accuracy.followup.abs[i] = df.attributes.subj$accuracy.followup.abs[att.row]
# df.demo$accuracy.scaled[i] = df.attributes.subj$accuracy.scaled[att.row]
# df.demo$accuracy.best[i] = df.attributes.subj$accuracy.best[att.row]
# df.demo$accuracy.followup.best[i] = df.attributes.subj$accuracy.followup.best[att.row]
# df.demo$mse[i] = df.attributes.subj$mse[att.row]
# df.demo$mse.abs[i] = df.attributes.subj$mse.abs[att.row]
# df.demo$mse.followup[i] = df.attributes.subj$mse.followup[att.row]
# df.demo$mse.followup.abs[i] = df.attributes.subj$mse.followup.abs[att.row]
# df.demo$mse.best[i] = df.attributes.subj$mse.best[att.row]
# df.demo$mse.best.abs[i] = df.attributes.subj$mse.best.abs[att.row]
# df.demo$mse.followup.best[i] = df.attributes.subj$mse.followup.best[att.row]
# df.demo$mse.followup.best.abs[i] = df.attributes.subj$mse.followup.best.abs[att.row]
}
## get inv temps
df.temp.wad = read.csv('fitted_empirical_temps_WAD.csv', header = F)
df.temp.wp = read.csv('fitted_empirical_temps_WP.csv', header = F)
df.temp.ew = read.csv('fitted_empirical_temps_EW.csv', header = F)
df.temp.tal = read.csv('fitted_empirical_temps_TAL.csv', header = F)
df.temp.lex = read.csv('fitted_empirical_temps_LEXNB.csv', header = F)
df.temp.lexb = read.csv('fitted_empirical_temps_LEXB.csv', header = F)
df.temp = bind_cols(df.temp.wad, df.temp.wp, df.temp.ew, df.temp.tal, df.temp.lex, df.temp.lexb)
for (i in 1:nrow(df.demo)) {
df.demo$inv.temp[i] = df.temp[i,df.demo$best.model.num[i]]
}
## get avg option diffs
# df.optiondiffs = read.csv('option_diffs.csv', header = F)
# df.demo$option.diff.avg = df.optiondiffs$V1
# df.demo$option.diff.choiceprob = df.optiondiffs$V2
# df.demo$option.diff.sd = df.optiondiffs$V3
# these are my weird attempts at doing split-half reliability estimates
# df.s2.subj.split = df.s2 %>% mutate(trial_half = factor(trial %in% combs[,i], c(F,T), c('First Half', 'Second Half'))) %>%
#   group_by(subject, trial_half) %>%
#   summarize(accuracy = cor(fitted.weight.abs, rating))
# combs = combn(1:18,9)
# df.s2.grouped = df.s2 %>% group_by(subject)
# shr = numeric(ncol(combs))
# for (i in 1:ncol(combs)) {
#   acc1 = (df.s2.grouped %>% filter(trial %in% combs[,i]) %>% summarize(accuracy = cor(fitted.weight.abs, rating)))$accuracy
#   acc2 = (df.s2.grouped %>% filter(!(trial %in% combs[,i])) %>% summarize(accuracy = cor(fitted.weight.abs, rating)))$accuracy
#   shr[i] = cor(acc1, acc2)
# }
df.browser = read.csv('browser_events.csv', stringsAsFactors = F)
df.browser.subj = df.browser %>%
filter(browser_event == 'blur') %>%
group_by(subject) %>%
summarize(num.blur = n())
df.browser = read.csv('browser_events.csv', stringsAsFactors = F)
df.browser.subj = df.browser %>%
filter(browser_event == 'blur') %>%
group_by(subject) %>%
summarize(num.blur = n())
df.demo$attention
df.s1.subj$pct_left
exclude.subj = c()
for (subj in subjlist) {
demo.row = df.demo$subject == subj
s1.subj = df.s1.subj$subject == subj
browser.row = df.browser.subj$subject == subj
if (df.demo$instruction_times_median[demo.row] < 2 |
df.s1.subj$pct_left[s1.subj] > .8 |
df.s1.subj$pct_left[s1.subj] < .2 |
df.s1.subj$num_trials[s1.subj] != 100 |
df.demo$attention[demo.row] < 50 |
df.demo$below.chance[demo.row] |
#subj %in% exclude.subj.ant |
#(!is.na(df.demo$instruction_times_followup_median[demo.row]) && df.demo$instruction_times_followup_median[demo.row] < 2) |
(any(browser.row) && df.browser.subj$num.blur[df.browser.subj$subject == subj] > 20)) {
exclude.subj = c(exclude.subj, subj)
}
}
df.demo.filt = df.demo %>% filter(!(subject %in% exclude.subj))
df.s1.filt = df.s1 %>% filter(!(subject %in% exclude.subj))
df.s1.subj.filt = df.s1.subj %>% filter(!(subject %in% exclude.subj))
df.s1.practice.filt = df.s1.practice %>% filter(!(subject %in% exclude.subj))
df.s2.filt = df.s2 %>% filter(!(subject %in% exclude.subj))
df.attributes.filt = df.attributes %>% filter(!(subject %in% exclude.subj))
df.attributes.subj.filt = df.attributes.subj %>% filter(!(subject %in% exclude.subj))
df.cv.filt = df.cv %>% filter(!(subject %in% exclude.subj))
df.cv.norm.filt = df.cv.norm %>% filter(!(subject %in% exclude.subj))
df.cv.best.filt = df.cv.best %>% filter(!(subject %in% exclude.subj))
df.cc.filt = df.cc %>% filter(!(subject %in% exclude.subj))
df.cc.subj.filt = df.cc.subj %>% filter(!(subject %in% exclude.subj))
## linearity
mean(df.attributes.filt$linear[df.attributes.filt$rating.wad > .1])
df.attributes.byatt = df.attributes %>% #.filt %>% filter(rating.wad > .1) %>%
group_by(attribute) %>%
summarize(linear = mean(linear), almost.linear = mean(almost.linear))
df.attributes.byatt
plot(df.attributes.subj.filt$linear, df.demo.filt$best.model.ll.magnitude)
cor.test(df.attributes.subj.filt$linear, df.demo.filt$best.model.ll.magnitude)
## appropriateness
hist(df.demo.filt$appropriateness)
## comprehension checks
ggplot(df.cc.filt, aes(x = value)) +
geom_histogram() +
geom_vline(aes(xintercept = answer), color = 'red', linetype = 'dashed') +
geom_vline(aes(xintercept = 50), color = 'black', linetype = 'dashed') +
facet_wrap(~name) +
xlab('Response (0-100)') + ylab('# of Subjects') +
scale_x_continuous(limits = c(-10,110), breaks = c(0,50,100)) +
scale_y_continuous()
## check out model fits
# which models were the best fits?
ggplot(df.demo.filt, aes(x = best.model.fac)) +
geom_bar(position = 'dodge', color = 'white') +
theme_black() +
labs(x = '\nBest-fitting model', y = '# of subjects')
# how good were the model fits?
ggplot(df.demo.filt, aes(x = best.model.ll.magnitude)) +
geom_histogram(color = 'white', bins = 20) +
labs(x = "\nAvg out-of-sample likelihood\nof best model",
y = "# of subjects") +
scale_y_continuous(breaks = NULL) +
geom_vline(xintercept = 1, color = 'red', linetype = 'dashed') +
geom_vline(xintercept = .5, color = 'red', linetype = 'dashed') +
theme_black()
get.ci(df.demo.filt$best.model.ll.magnitude)
ggplot(df.demo.filt, aes(x = best.model.rnd.magnitude2)) +
geom_histogram(color = 'white', bins = 25) +
labs(x = '\n% correct out-of-sample choices\nof best model',
y = "# of subjects") +
scale_y_continuous(breaks = NULL) +
geom_vline(xintercept = 1, color = 'red', linetype = 'dashed') +
geom_vline(xintercept = .5, color = 'red', linetype = 'dashed') +
theme_black()
get.ci(df.demo.filt$best.model.rnd.magnitude)
# how varied were the model fits?
ggplot(df.demo.filt, aes(x = sd.model.ll)) +
geom_histogram(color = 'white', bins = 20) +
labs(x = "\nAvg out-of-sample likelihood\nof best model",
y = "# of subjects") +
scale_y_continuous(breaks = NULL) +
theme_black()
df.cv.filt$avg.model.ll = df.demo.filt$avg.model.ll
df.cv.filt$mse.best = df.demo.filt$mse.best
df.cv.filt$chosen.model.fac = df.demo.filt$chosen.model.fac
df.cv.long = df.cv.filt %>%
mutate(subject.num = factor(subject.num),
subject.num = fct_reorder(subject.num, avg.model.ll)) %>%
pivot_longer(!c(subject.num,avg.model.ll,chosen.model.fac,subject), names_to = 'model', values_to = 'll') %>%
arrange(avg.model.ll) %>%
mutate(chosen.model = chosen.model.fac == model)
ggplot(df.cv.long,
aes(x = ll, y = subject.num, group = subject.num, color = subject.num, shape = model)) +
geom_point(size = 2) +
guides(group = 'none', color = 'none') +#,
#alpha = guide_legend(title = 'Parameter accuracy\n(higher is better)')) +
#scale_color_brewer(palette = 'Set3') +
#theme_black()+
scale_y_discrete(expand = c(-.5,0)) +
scale_colour_manual(values=rep(brewer.pal(9,"Set1"),times=100))+
theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) +
labs(x = '\nAvg out-of-sample model likelihood',
y = 'Subject')
ggplot(df.demo.filt, aes(x = appropriateness, y = best.model.ll.magnitude)) +
geom_point(color = 'gray') +
geom_smooth(method='lm', color = 'white') +
theme_black() +
labs(x = '\nRating', y = 'Out-of-sample likelihood\nof best model')
## process awareness
# what models did subjects report using?
ggplot(df.demo.filt, aes(x = chosen.model.fac)) +
geom_bar(position = 'dodge', color = 'white') +
theme_black() +
labs(x = '\nSelf-reported model', y = '# of subjects')
ggplot(df.demo.filt, aes(x = best.model.fac, fill = chosen.model.fac)) +
geom_bar(position = 'dodge') +
labs(x = 'Best fitted model', y = '') +
guides(fill = guide_legend(title = 'Reported model', title.position = 'top', title.hjust = .5)) +
theme(legend.position = 'top') +
scale_y_continuous(breaks = NULL)
df.demo.heat = df.demo %>% group_by(chosen.model.fac, best.model.fac) %>%
summarize(num.subj = n())
ggplot(df.demo.heat, aes(x = best.model.fac, y = chosen.model.fac,
fill = num.subj)) +
geom_tile() +
labs(y = '\nSelf-reported model', x = 'Best-fitting model') +
#scale_fill_brewer(palette = 'YlOrRd') +
guides(fill = guide_colorbar(title = '# of subjects')) +
theme_black()
df.s1.subj.filt
hist(df.s1.subj.filt$total.time
)
median(df.s1.subj$total.time)
df.demo.filt$total_time_real
median(df.demo.filt$total_time_real)
View(df.s2.filt)
test = df.s2.filt %>% filter(type = 'direction')
test = df.s2.filt %>% filter(type == 'direction')
median(test$rt)
test2 = test %>% group_by(subject) %>% summarize(rt = sum(rt))
median(test2$rt)
median(test2$rt) / 60
median(test2$rt) / 1000
median(test2$rt) / 60000
# meditation
test = df.demo.filt %>% group_by(meditation_exp1) %>%
summarize(accuracy.best.best.m = mean(accuracy.best.best, na.rm = T),
accuracy.best.best.se = se(accuracy.best.best),
accuracy.chosen.chosen.m = mean(accuracy.chosen.chosen, na.rm = T),
accuracy.chosen.chosen.se = se(accuracy.chosen.chosen),
chosen.model.ll.m = mean(chosen.model.ll, na.rm = T),
chosen.model.ll.se = se(chosen.model.ll),
chose.correct.model.m = mean(chose.correct.model, na.rm = T),
chose.correct.model.se = se.prop(chose.correct.model))
ggplot(test, aes(x = meditation_exp1, y = chosen.model.ll.m)) +
geom_point() +
geom_errorbar(aes(ymin = chosen.model.ll.m - chosen.model.ll.se, ymax = chosen.model.ll.m + chosen.model.ll.se))
save.image('analysis.rdata')
