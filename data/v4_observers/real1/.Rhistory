summarize(num_same = sum(same & (rating.wad > 10)),
accuracy.wad.chosen = cor(fitted.weight.chosen, rating.wad.signed, method = 'kendall'),
accuracy.wad.best = cor(fitted.weight.best, rating.wad.signed, method = 'kendall'),
accuracy.ew.chosen = cor(fitted.weight.chosen, rating.ew.signed, method = 'kendall'),
accuracy.ew.best = cor(fitted.weight.best, rating.ew.signed, method = 'kendall'),
accuracy.lex.chosen = cor(fitted.weight.chosen, rating.lex.signed, method = 'kendall'),
accuracy.lex.best = cor(fitted.weight.best, rating.lex.signed, method = 'kendall'),
accuracy.chosen.best = cor(fitted.weight.best, rating.chosen.signed, method = 'kendall'),
accuracy.chosen.chosen = cor(fitted.weight.chosen, rating.chosen.signed, method = 'kendall'),
accuracy.best.best = cor(fitted.weight.best, rating.best.signed))
cols.to.xfer = colnames(df.attributes.subj %>% select(!subject))
for (i in 1:nrow(df.demo)) {
att.row = df.attributes.subj$subject == df.demo$subject[i]
for (cur.col in cols.to.xfer) {
df.demo[i,cur.col] = df.attributes.subj[att.row, cur.col]
}
}
## get inv temps
df.temp.wad = read.csv(paste0(target.path, 'fitted_empirical_temps_WAD.csv'), header = F)
df.temp.wp = read.csv(paste0(target.path, 'fitted_empirical_temps_WP.csv'), header = F)
df.temp.ew = read.csv(paste0(target.path, 'fitted_empirical_temps_EW.csv'), header = F)
df.temp.tal = read.csv(paste0(target.path, 'fitted_empirical_temps_TAL.csv'), header = F)
df.temp.lex = read.csv(paste0(target.path, 'fitted_empirical_temps_LEXNB.csv'), header = F)
df.temp.lexb = read.csv(paste0(target.path, 'fitted_empirical_temps_LEXB.csv'), header = F)
df.temp = bind_cols(df.temp.wad, df.temp.wp, df.temp.ew, df.temp.tal, df.temp.lex, df.temp.lexb)
df.demo$inv.temp = NA
for (i in 1:nrow(df.demo)) {
if (!is.na(df.demo$target_num_mapped[i])) {
df.demo$inv.temp[i] = df.temp[df.demo$target_num_mapped[i],df.demo$best.model.num[i]]
}
}
## get avg option diffs
# df.optiondiffs = read.csv('option_diffs.csv', header = F)
# df.demo$option.diff.avg = df.optiondiffs$V1
# df.demo$option.diff.choiceprob = df.optiondiffs$V2
# df.demo$option.diff.sd = df.optiondiffs$V3
# these are my weird attempts at doing split-half reliability estimates
# df.s2.subj.split = df.s2 %>% mutate(trial_half = factor(trial %in% combs[,i], c(F,T), c('First Half', 'Second Half'))) %>%
#   group_by(subject, trial_half) %>%
#   summarize(accuracy = cor(fitted.weight.abs, rating))
# combs = combn(1:18,9)
# df.s2.grouped = df.s2 %>% group_by(subject)
# shr = numeric(ncol(combs))
# for (i in 1:ncol(combs)) {
#   acc1 = (df.s2.grouped %>% filter(trial %in% combs[,i]) %>% summarize(accuracy = cor(fitted.weight.abs, rating)))$accuracy
#   acc2 = (df.s2.grouped %>% filter(!(trial %in% combs[,i])) %>% summarize(accuracy = cor(fitted.weight.abs, rating)))$accuracy
#   shr[i] = cor(acc1, acc2)
# }
df.browser = read.csv('browser_events.csv', stringsAsFactors = F)
df.browser.subj = df.browser %>%
filter(browser_event == 'blur') %>%
group_by(subject) %>%
summarize(num.blur = n())
exclude.subj = c()
for (subj in subjlist) {
demo.row = df.demo$subject == subj
s1.subj = df.s1.subj$subject == subj
browser.row = df.browser.subj$subject == subj
if (df.demo$instruction_times_median[demo.row] < 2 |
df.s1.subj$num_trials[s1.subj] != 100 |
df.s1.subj$pct_correct[s1.subj] < 0.95 |
df.demo$attention[demo.row] < 50 |
#df.attributes.subj$num_same[df.attributes.subj$subject == subj] > 0 |
df.demo$below.chance[demo.row] |
is.na(df.demo$target_num_mapped[demo.row]) |
#subj %in% exclude.subj.ant |
#(!is.na(df.demo$instruction_times_followup_median[demo.row]) && df.demo$instruction_times_followup_median[demo.row] < 2) |
(any(browser.row) && df.browser.subj$num.blur[df.browser.subj$subject == subj] > 20)) {
exclude.subj = c(exclude.subj, subj)
}
}
df.demo.filt = df.demo %>% filter(!(subject %in% exclude.subj))
df.s1.filt = df.s1 %>% filter(!(subject %in% exclude.subj))
df.s2.filt = df.s2 %>% filter(!(subject %in% exclude.subj))
df.attributes.filt = df.attributes %>% filter(!(subject %in% exclude.subj))
df.attributes.subj.filt = df.attributes.subj %>% filter(!(subject %in% exclude.subj))
df.cv.filt = df.cv %>% filter(!(subject %in% exclude.subj))
df.cv.norm.filt = df.cv.norm %>% filter(!(subject %in% exclude.subj))
df.cv.best.filt = df.cv.best %>% filter(!(subject %in% exclude.subj))
df.cc.filt = df.cc %>% filter(!(subject %in% exclude.subj))
df.cc.subj.filt = df.cc.subj %>% filter(!(subject %in% exclude.subj))
exclude.subj = c()
for (subj in subjlist) {
demo.row = df.demo$subject == subj
s1.subj = df.s1.subj$subject == subj
browser.row = df.browser.subj$subject == subj
if (df.demo$instruction_times_median[demo.row] < 2 |
df.s1.subj$num_trials[s1.subj] != 100 |
df.s1.subj$pct_correct[s1.subj] < 0.95 |
df.demo$attention[demo.row] < 50 |
#df.attributes.subj$num_same[df.attributes.subj$subject == subj] > 0 |
df.demo$below.chance[demo.row] |
is.na(df.demo$target_num_mapped[demo.row]) |
#subj %in% exclude.subj.ant |
#(!is.na(df.demo$instruction_times_followup_median[demo.row]) && df.demo$instruction_times_followup_median[demo.row] < 2) |
(any(browser.row) && df.browser.subj$num.blur[df.browser.subj$subject == subj] > 20)) {
exclude.subj = c(exclude.subj, subj)
}
}
df.demo.filt = df.demo %>% filter(!(subject %in% exclude.subj))
df.s1.filt = df.s1 %>% filter(!(subject %in% exclude.subj))
df.s2.filt = df.s2 %>% filter(!(subject %in% exclude.subj))
df.attributes.filt = df.attributes %>% filter(!(subject %in% exclude.subj))
df.attributes.subj.filt = df.attributes.subj %>% filter(!(subject %in% exclude.subj))
df.cv.filt = df.cv %>% filter(!(subject %in% exclude.subj))
version = '';
## get mapping
df.map = read.csv(paste0(target.path, 'observer_mapping.csv'), header = F)
colnames(df.map) = c('subject', 'subject.num')
## get cross-validation results
# non-normalized version
df.cv = read.csv(paste0(target.path, 'cv_results',version,'.csv'), header = F)
colnames(df.cv) = models
df.cv$subject.num = df.map$subject.num
df.cv$subject = df.map$subject
df.cv$avg.model.ll = rowMeans(df.cv[,1:length(models)])
df.cv$var.model.ll = apply(df.cv[,1:length(models)], 1, var)
df.cv$sd.model.ll = sqrt(df.cv$var.model.ll)
# likelihoods of best model
df.cv.best = read.csv(paste0(target.path, 'cv_results_best',version,'.csv'), header = F)
df.cv.best$subject = df.map$subject
df.cv.best$subject.num = df.map$subject.num
colnames(df.cv.best)[2:3] = c('below.chance', 'best.model.ll.magnitude')
# ll version
df.cv.norm = read.csv(paste0(target.path, 'cv_results_normalized',version,'.csv'), header = F)
colnames(df.cv.norm) = models
df.cv.norm$subject.num = df.map$subject.num
df.cv.norm$subject = df.map$subject
# rounded version
df.cv.rnd = read.csv(paste0(target.path, 'cv_results_rounded',version,'.csv'), header = F)
colnames(df.cv.rnd) = models
df.cv.rnd$subject.num = df.map$subject.num
df.cv.rnd$subject = df.map$subject
# add all to demo
df.demo$target_num_mapped = NA
df.demo$avg.model.ll = NA
df.demo$var.model.ll = NA
df.demo$sd.model.ll = NA
df.demo$below.chance = NA
df.demo$best.model.ll.magnitude = NA
df.demo$best.model.nums = NA
df.demo$multiple.bests = NA
df.demo$best.model.num = NA
df.demo$chosen.model.ll = NA
df.demo$chosen.model.ll.unnormed = NA
df.demo$chosen.model.rank = NA
df.demo$chose.correct.model = NA
df.demo$best.model.rnd.magnitude2 = NA
for (i in 1:nrow(df.demo)) {
#target.id = df.demo$target_id[i]
#target.mapped.num = df.map$subject.num[df.map$subject == target.id]
target.mapped.num = df.demo$target_id_num[i]
if (length(target.mapped.num) > 0) {
df.demo$target_num_mapped[i] = target.mapped.num
df.demo$avg.model.ll[i] = df.cv$avg.model.ll[target.mapped.num]
df.demo$var.model.ll[i] = df.cv$var.model.ll[target.mapped.num]
df.demo$sd.model.ll[i] = df.cv$sd.model.ll[target.mapped.num]
df.demo$below.chance[i] = df.cv.best$below.chance[target.mapped.num]
df.demo$best.model.ll.magnitude[i] = df.cv.best$best.model.ll.magnitude[target.mapped.num]
df.demo$best.model.nums[i] = list(which(df.cv.norm[target.mapped.num,1:length(models)] == max(df.cv.norm[target.mapped.num,1:length(models)], na.rm = T)))
df.demo$multiple.bests[i] = length(df.demo$best.model.nums[i][[1]]) > 1
df.demo$best.model.num[i] = max(df.demo$best.model.nums[i][[1]])
df.demo$chosen.model.ll[i] = df.cv.norm[target.mapped.num, df.demo$chosen.model.num[i]]
df.demo$chosen.model.ll.unnormed[i] = df.cv[target.mapped.num, df.demo$chosen.model.num[i]]
df.demo$chosen.model.rank[i] = rank(-df.cv.norm[target.mapped.num,1:length(models)])[df.demo$chosen.model.num[i]]
df.demo$chose.correct.model[i] = df.demo$chosen.model.num[i] %in% df.demo$best.model.nums[i][[1]]
df.demo$best.model.rnd.magnitude2[i] = df.cv.rnd[target.mapped.num,df.demo$best.model.num[i]]
}
}
df.demo = df.demo %>%
mutate(best.model = models[best.model.num],
best.model.fac = factor(best.model, models.order, models.order),
best.model.oneatt = factor(models.one.att[best.model.num], one.att.levels),
best.model.binwts = factor(models.bin.wts[best.model.num], bin.wts.levels),
best.model.binatts = factor(models.bin.atts[best.model.num], bin.atts.levels),
chosen.model.dist = best.model.ll.magnitude - chosen.model.ll.unnormed)
# add to df.attributes
for (i in 1:nrow(df.attributes)) {
row.demo = df.demo$subject == df.attributes$subject[i]
df.attributes$target_num_mapped[i] = df.demo$target_num_mapped[row.demo]
df.attributes$best.model.num[i] = df.demo$best.model.num[row.demo]
df.attributes$rating.best[i] = ifelse(df.demo$best.model.oneatt[row.demo] == 'One',
df.attributes$rating.lex[i],
ifelse(df.demo$best.model.binwts[row.demo] == 'Binary',
df.attributes$rating.ew[i],
df.attributes$rating.wad[i]))
}
df.attributes = df.attributes %>% mutate(rating.best.signed = rating.best * direction)
## get weights
df.fitted.wad = read.csv(paste0(target.path, 'fitted_empirical_weights_WAD.csv'), header = F)
df.fitted.wp = read.csv(paste0(target.path, 'fitted_empirical_weights_WP.csv'), header = F)
df.fitted.ew = read.csv(paste0(target.path, 'fitted_empirical_weights_EW.csv'), header = F)
df.fitted.tal = read.csv(paste0(target.path, 'fitted_empirical_weights_TAL.csv'), header = F)
df.fitted.lex.raw = read.csv(paste0(target.path, 'fitted_empirical_weights_LEXNB.csv'), header = F)
df.fitted.lexb.raw = read.csv(paste0(target.path, 'fitted_empirical_weights_LEXB.csv'), header = F)
colnames(df.fitted.wad) = atts
colnames(df.fitted.wp) = atts
colnames(df.fitted.ew) = atts
colnames(df.fitted.tal) = atts
df.fitted.lex = df.fitted.wad
for (i in 1:nrow(df.fitted.lex)) {
for (att in 1:length(atts)) {
if (df.fitted.lex.raw$V1[i] == att) {
df.fitted.lex[i,att] = ifelse(df.fitted.lex.raw$V2[i] == 1, 1, -1)
} else {
df.fitted.lex[i,att] = 0
}
}
}
df.fitted.lexb = df.fitted.wad
for (i in 1:nrow(df.fitted.lexb)) {
for (att in 1:length(atts)) {
if (df.fitted.lexb.raw$V1[i] == att) {
df.fitted.lexb[i,att] = ifelse(df.fitted.lexb.raw$V2[i] == 1, 1, -1)
} else {
df.fitted.lexb[i,att] = 0
}
}
}
fitted.weights = list(df.fitted.wad, df.fitted.wp, df.fitted.ew, df.fitted.tal, df.fitted.lex, df.fitted.lexb)
df.attributes[c('fitted.weight.chosen', 'fitted.weight.best',
'fitted.weight.wad', 'fitted.weight.wp',
'fitted.weight.ew', 'fitted.weight.tal',
'fitted.weight.lex', 'fitted.weight.lexb')] = NA
for (i in 1:nrow(df.attributes)) {
if (!is.na(df.attributes$target_num_mapped[i])) {
df.attributes$fitted.weight.chosen[i] = fitted.weights[[df.attributes$chosen.model.num[i]]][df.attributes$target_num_mapped[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.best[i] = fitted.weights[[df.attributes$best.model.num[i]]][df.attributes$target_num_mapped[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.wad[i] = fitted.weights[[1]][df.attributes$target_num_mapped[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.wp[i] = fitted.weights[[2]][df.attributes$target_num_mapped[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.ew[i] = fitted.weights[[3]][df.attributes$target_num_mapped[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.tal[i] = fitted.weights[[4]][df.attributes$target_num_mapped[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.lex[i] = fitted.weights[[5]][df.attributes$target_num_mapped[i],df.attributes$attribute[i]]
df.attributes$fitted.weight.lexb[i] = fitted.weights[[6]][df.attributes$target_num_mapped[i],df.attributes$attribute[i]]
}
}
df.attributes = df.attributes %>%
mutate(fitted.weight.chosen.abs = abs(fitted.weight.chosen),
fitted.weight.best.abs = abs(fitted.weight.best),
fitted.weight.wad.abs = abs(fitted.weight.wad))
# get normalized per-subject fitted weights and ratings
# subjects = unique(df.attributes$subject.num)
# for (i in subjects) {
#   cur.rows = df.attributes$subject.num == i
#   df.attributes$rating.wad.signed.scaled[cur.rows] = scale(df.attributes$rating.wad.signed[cur.rows])
#   df.attributes$fitted.weight.chosen.scaled[cur.rows] = scale(df.attributes$fitted.weight.chosen[cur.rows])
#   #df.s2$fitted.weight.lm.scaled[cur.rows] = scale(df.s2$fitted.weight.lm[cur.rows])
# }
# get subject-level accuracies
df.attributes.subj = df.attributes %>% group_by(subject) %>%
summarize(num_same = sum(same & (rating.wad > 10)),
accuracy.wad.chosen = cor(fitted.weight.chosen, rating.wad.signed, method = 'kendall'),
accuracy.wad.best = cor(fitted.weight.best, rating.wad.signed, method = 'kendall'),
accuracy.ew.chosen = cor(fitted.weight.chosen, rating.ew.signed, method = 'kendall'),
accuracy.ew.best = cor(fitted.weight.best, rating.ew.signed, method = 'kendall'),
accuracy.lex.chosen = cor(fitted.weight.chosen, rating.lex.signed, method = 'kendall'),
accuracy.lex.best = cor(fitted.weight.best, rating.lex.signed, method = 'kendall'),
accuracy.chosen.best = cor(fitted.weight.best, rating.chosen.signed, method = 'kendall'),
accuracy.chosen.chosen = cor(fitted.weight.chosen, rating.chosen.signed, method = 'kendall'),
accuracy.best.best = cor(fitted.weight.best, rating.best.signed))
cols.to.xfer = colnames(df.attributes.subj %>% select(!subject))
for (i in 1:nrow(df.demo)) {
att.row = df.attributes.subj$subject == df.demo$subject[i]
for (cur.col in cols.to.xfer) {
df.demo[i,cur.col] = df.attributes.subj[att.row, cur.col]
}
}
## get inv temps
df.temp.wad = read.csv(paste0(target.path, 'fitted_empirical_temps_WAD.csv'), header = F)
df.temp.wp = read.csv(paste0(target.path, 'fitted_empirical_temps_WP.csv'), header = F)
df.temp.ew = read.csv(paste0(target.path, 'fitted_empirical_temps_EW.csv'), header = F)
df.temp.tal = read.csv(paste0(target.path, 'fitted_empirical_temps_TAL.csv'), header = F)
df.temp.lex = read.csv(paste0(target.path, 'fitted_empirical_temps_LEXNB.csv'), header = F)
df.temp.lexb = read.csv(paste0(target.path, 'fitted_empirical_temps_LEXB.csv'), header = F)
df.temp = bind_cols(df.temp.wad, df.temp.wp, df.temp.ew, df.temp.tal, df.temp.lex, df.temp.lexb)
df.demo$inv.temp = NA
for (i in 1:nrow(df.demo)) {
if (!is.na(df.demo$target_num_mapped[i])) {
df.demo$inv.temp[i] = df.temp[df.demo$target_num_mapped[i],df.demo$best.model.num[i]]
}
}
## get avg option diffs
# df.optiondiffs = read.csv('option_diffs.csv', header = F)
# df.demo$option.diff.avg = df.optiondiffs$V1
# df.demo$option.diff.choiceprob = df.optiondiffs$V2
# df.demo$option.diff.sd = df.optiondiffs$V3
# these are my weird attempts at doing split-half reliability estimates
# df.s2.subj.split = df.s2 %>% mutate(trial_half = factor(trial %in% combs[,i], c(F,T), c('First Half', 'Second Half'))) %>%
#   group_by(subject, trial_half) %>%
#   summarize(accuracy = cor(fitted.weight.abs, rating))
# combs = combn(1:18,9)
# df.s2.grouped = df.s2 %>% group_by(subject)
# shr = numeric(ncol(combs))
# for (i in 1:ncol(combs)) {
#   acc1 = (df.s2.grouped %>% filter(trial %in% combs[,i]) %>% summarize(accuracy = cor(fitted.weight.abs, rating)))$accuracy
#   acc2 = (df.s2.grouped %>% filter(!(trial %in% combs[,i])) %>% summarize(accuracy = cor(fitted.weight.abs, rating)))$accuracy
#   shr[i] = cor(acc1, acc2)
# }
exclude.subj = c()
for (subj in subjlist) {
demo.row = df.demo$subject == subj
s1.subj = df.s1.subj$subject == subj
browser.row = df.browser.subj$subject == subj
if (df.demo$instruction_times_median[demo.row] < 2 |
df.s1.subj$num_trials[s1.subj] != 100 |
df.s1.subj$pct_correct[s1.subj] < 0.95 |
df.demo$attention[demo.row] < 50 |
#df.attributes.subj$num_same[df.attributes.subj$subject == subj] > 0 |
df.demo$below.chance[demo.row] |
is.na(df.demo$target_num_mapped[demo.row]) |
#subj %in% exclude.subj.ant |
#(!is.na(df.demo$instruction_times_followup_median[demo.row]) && df.demo$instruction_times_followup_median[demo.row] < 2) |
(any(browser.row) && df.browser.subj$num.blur[df.browser.subj$subject == subj] > 20)) {
exclude.subj = c(exclude.subj, subj)
}
}
df.demo.filt = df.demo %>% filter(!(subject %in% exclude.subj))
df.s1.filt = df.s1 %>% filter(!(subject %in% exclude.subj))
df.s2.filt = df.s2 %>% filter(!(subject %in% exclude.subj))
df.attributes.filt = df.attributes %>% filter(!(subject %in% exclude.subj))
df.attributes.subj.filt = df.attributes.subj %>% filter(!(subject %in% exclude.subj))
df.cv.filt = df.cv %>% filter(!(subject %in% exclude.subj))
df.cv.norm.filt = df.cv.norm %>% filter(!(subject %in% exclude.subj))
df.cv.best.filt = df.cv.best %>% filter(!(subject %in% exclude.subj))
df.cc.filt = df.cc %>% filter(!(subject %in% exclude.subj))
df.cc.subj.filt = df.cc.subj %>% filter(!(subject %in% exclude.subj))
hist(df.demo.filt$target_id_num)
hist(df.demo.filt$target_id)
hist(df.demo.filt$target_num)
hist(df.demo.filt$target_id_num)
View(df.map)
test = df.demo.filt %>% group_by(target_id_num) %>%
summarize(num = n())
View(test)
test = df.demo %>% group_by(target_id_num) %>%
summarize(num = n())
246 / 300
df.demo.heat = df.demo %>% group_by(chosen.model.fac, best.model.fac) %>%
summarize(num.subj = n())
ggplot(df.demo.heat, aes(x = best.model.fac, y = chosen.model.fac,
fill = num.subj)) +
geom_tile() +
labs(y = '\nSelf-reported model', x = 'Best-fitting model') +
#scale_fill_brewer(palette = 'YlOrRd') +
guides(fill = guide_colorbar(title = '# of subjects')) +
theme_black()
pct.correct = mean(df.demo.filt$chose.correct.model)
pct.correct
## by feature
# lex
df.feature.oneatt = df.demo.filt %>% group_by(best.model.oneatt) %>%
summarize(lex_real.m = mean(lex_real),
lex_real.se = se(lex_real))
df.feature.oneatt.cc = df.demo.filt %>%
filter(cc.correct.lex == 2) %>%
group_by(best.model.oneatt) %>%
summarize(lex_real.m = mean(lex_real),
lex_real.se = se(lex_real))
ggplot(df.demo.filt, aes(x = lex_real, group = best.model.oneatt, fill = best.model.oneatt)) +
geom_histogram(alpha = .5, position = 'identity')
ggplot(df.demo.filt %>% filter(cc.correct.lex == 2), aes(x = lex_real, group = best.model.oneatt, fill = best.model.oneatt)) +
geom_histogram(alpha = .5, position = 'identity')
ggplot(df.feature.oneatt, aes(x = best.model.oneatt, y = lex_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = lex_real.m - lex_real.se, ymax = lex_real.m + lex_real.se))
ggplot(df.feature.oneatt.cc, aes(x = best.model.oneatt, y = lex_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = lex_real.m - lex_real.se, ymax = lex_real.m + lex_real.se))
ggplot(df.feature.oneatt, aes(x = best.model.oneatt, y = lex_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = lex_real.m - lex_real.se, ymax = lex_real.m + lex_real.se))
ggplot(df.feature.binwts, aes(x = best.model.binwts, y = binwts_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = binwts_real.m - binwts_real.se, ymax = binwts_real.m + binwts_real.se))
# binwts
df.feature.binwts = df.demo.filt %>% group_by(best.model.binwts) %>%
summarize(binwts_real.m = mean(binwts_real),
binwts_real.se = se(binwts_real))
df.feature.binwts.cc = df.demo.filt %>%
filter(cc.correct.binwts == 2) %>%
group_by(best.model.binwts) %>%
summarize(binwts_real.m = mean(binwts_real),
binwts_real.se = se(binwts_real))
ggplot(df.demo.filt, aes(x = binwts_real, group = best.model.binwts, fill = best.model.binwts)) +
geom_histogram(alpha = .5, position = 'identity')
ggplot(df.demo.filt %>% filter(cc.correct.lex == 2), aes(x = binwts_real, group = best.model.oneatt, fill = best.model.oneatt)) +
geom_histogram(alpha = .5, position = 'identity')
ggplot(df.feature.binwts, aes(x = best.model.binwts, y = binwts_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = binwts_real.m - binwts_real.se, ymax = binwts_real.m + binwts_real.se))
# binatts
df.feature.binatts = df.demo.filt %>% group_by(best.model.binatts) %>%
summarize(binatts_real.m = mean(binatts_real),
binatts_real.se = se(binatts_real))
df.feature.binatts.cc = df.demo.filt %>%
filter(cc.correct.binatts == 2) %>%
group_by(best.model.binatts) %>%
summarize(binatts_real.m = mean(binatts_real),
binatts_real.se = se(binatts_real))
ggplot(df.demo.filt, aes(x = binatts_real, group = best.model.binatts, fill = best.model.binatts)) +
geom_histogram(alpha = .5, position = 'identity')
ggplot(df.demo.filt %>% filter(cc.correct.lex == 2), aes(x = binatts_real, group = best.model.oneatt, fill = best.model.oneatt)) +
geom_histogram(alpha = .5, position = 'identity')
ggplot(df.feature.binatts, aes(x = best.model.binatts, y = binatts_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = binatts_real.m - binatts_real.se, ymax = binatts_real.m + binatts_real.se))
rand.lls = numeric(1000)
rand.dists = numeric(1000)
for (i in 1:length(rand.lls)) {
nrow.cv = nrow(df.cv.norm.filt)
rnd.choices = sample(length(models),nrow.cv,replace=T)
test = numeric(nrow.cv)
test2 = numeric(nrow.cv)
for (j in 1:nrow.cv) {
test[j] = df.cv.norm.filt[j,rnd.choices[j]]
test2[j] = df.demo$best.model.ll.magnitude[j] - df.cv.filt[j,rnd.choices[j]]
}
rand.lls[i] = mean(test)
rand.dists[i] = mean(test2)
}
ggplot(df.demo.filt, aes(x = chosen.model.ll)) +
geom_histogram(color = 'white', bins = 25) +
labs(x = "\nOOS likelihood of reported model\n(normalized so worst model = 0, best = 1)",
y = "# of subjects") +
scale_y_continuous(breaks = NULL) +
theme_black() +
geom_vline(xintercept = mean(df.demo.filt$chosen.model.ll), linetype = 1, color = 'gray') +
geom_vline(xintercept = mean(rand.lls), linetype = 'dashed', color = 'gray')
get.ci(df.demo.filt$chosen.model.ll)
save.image('analysis.rdata')
ggplot(df.demo.filt, aes(x = accuracy.best.best)) +
geom_histogram(alpha = .3, fill = 'gray', color = 'white') +
#geom_vline(xintercept = mean(rand.errs), linetype = 'dashed', color = 'gray') +
#geom_vline(xintercept = mean(df.demo.filt$accuracy), linetype = 1, color = 'gray') +
#labs(x = '\nMean squared error\n(compared to fitted params of reported model)', y = '# of subjects') +
scale_y_continuous(limits = c(0,25), breaks = NULL) +
#scale_x_continuous(limits = c(-.05,.55), breaks = c(0, .25, .5, .75)) +
theme_black()
mean(df.demo.filt$accuracy.best.best)
mean(df.demo.filt$accuracy.best.best,na.rm=T)
df.feature.oneatt.cc = df.demo.filt %>%
filter(cc.correct.lex == 2) %>%
group_by(best.model.oneatt) %>%
summarize(lex_real.m = mean(lex_real),
lex_real.se = se(lex_real))
ggplot(df.feature.oneatt.cc, aes(x = best.model.oneatt, y = lex_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = lex_real.m - lex_real.se, ymax = lex_real.m + lex_real.se))
ggplot(df.feature.oneatt, aes(x = best.model.oneatt, y = lex_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = lex_real.m - lex_real.se, ymax = lex_real.m + lex_real.se))
ggplot(df.feature.oneatt.cc, aes(x = best.model.oneatt, y = lex_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = lex_real.m - lex_real.se, ymax = lex_real.m + lex_real.se))
ggplot(df.feature.binwts.cc, aes(x = best.model.binwts, y = binwts_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = binwts_real.m - binwts_real.se, ymax = binwts_real.m + binwts_real.se))
ggplot(df.feature.binatts.cc, aes(x = best.model.binatts, y = binatts_real.m)) +
geom_point() +
geom_errorbar(aes(ymin = binatts_real.m - binatts_real.se, ymax = binatts_real.m + binatts_real.se))
df.demo.filt = df.demo.filt %>% mutate(
oneatt.correct = chosen.oneatt == best.model.oneatt,
binwts.correct = chosen.binwts == best.model.binwts,
binatts.correct = chosen.binatts == best.model.binatts
)
hist(df.demo.filt$oneatt.correct)
df.demo.filt$oneatt.correct
mean(df.demo.filt$oneatt.correct)
mean(df.demo.filt$binwts.correct)
mean(df.demo.filt$oneatt.correct,na.rm=T)
mean(df.demo.filt$binwts.correct,na.rm=T)
mean(df.demo.filt$binatts.correct,na.rm=T)
save.image('analysis.rdata')
load("/Users/adam/Me/Psychology/Projects/ma_choice/git/data/v4/real1/analysis.rdata")
df.demo.filt = df.demo.filt %>% mutate(
oneatt.correct = chosen.oneatt == best.model.oneatt,
binwts.correct = chosen.binwts == best.model.binwts,
binatts.correct = chosen.binatts == best.model.binatts
)
mean(df.demo.filt$oneatt.correct,na.rm=T)
mean(df.demo.filt$binwts.correct,na.rm=T)
mean(df.demo.filt$binatts.correct,na.rm=T)
se.prop(df.demo.filt$oneatt.correct)
.64 - 1.96*.02955
mean(df.demo.filt$binatts.correct,na.rm=T)
get.ci(df.demo.filt$oneatt.correct)
get.ci(df.demo.filt$binatts.correct,na.rm=T)
get.ci(df.demo.filt$binatts.correct)
get.ci(df.demo.filt$binwts.correct)
get.ci(df.demo.filt$chosen.model.ll)
get.ci(df.demo.filt$accuracy.best.best)
rm(list=ls())
load("/Users/adam/Me/Psychology/Projects/ma_choice/git/data/v4_observers/real1/analysis.rdata")
get.ci(df.demo.filt$oneatt.correct)
get.ci(df.demo.filt$binwts.correct)
get.ci(df.demo.filt$binatts.correct)
get.ci(df.demo.filt$pct.correct)
get.ci.prop = function(x) {return(c(mean(x,na.rm = T) - 1.96*se.prop(x), mean(x, na.rm = T), mean(x, na.rm = T) + 1.96*se.prop(x)))}
get.ci.prop = function(x) {return(c(mean(x,na.rm = T) - 1.96*se.prop(x), mean(x, na.rm = T), mean(x, na.rm = T) + 1.96*se.prop(x)))}
get.ci.prop(df.demo.filt$oneatt.correct)
get.ci.prop(df.demo.filt$binwts.correct)
get.ci.prop(df.demo.filt$binatts.correct)
get.ci.prop(df.demo.filt$pct.correct)
get.ci.prop(df.demo.filt$chose.correct.model)
rm(list=ls())
load("/Users/adam/Me/Psychology/Projects/ma_choice/git/data/v4/real1/analysis.rdata")
get.ci(df.demo.filt$chose.correct.model)
rm(list=ls())
load("/Users/adam/Me/Psychology/Projects/ma_choice/git/data/v4_observers/real1/analysis.rdata")
View(df.demo)
paste(df.demo$assignmentId, collapse = ",")
write(paste(df.demo$assignmentId, collapse = ","), 'followup_list.txt')
